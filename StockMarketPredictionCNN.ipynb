{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1F5LK4ch1EHqpeW690HR-PdPqxH8yZ4xU","timestamp":1722653874711}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xMJ_7623Grw6"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import SGD\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","source":["# Generate dummy data\n","np.random.seed(42)\n","# Initialize data\n","num_samples = 1000\n","num_features = 5\n","importance_weight = 100.0 # Scale up the weights x times\n","importance_bias = 10.0 # Scale up the bias x times\n","importance_noise = 10.0 # Scale up the noise x times\n","outlier_value = 10000.0 # Scaling the outlier x times\n","\n","\n","data_input = np.random.rand(num_samples, num_features)  # n samples of m features each\n","true_weights = np.random.rand(num_features) * importance_weight # True feature weights\n","true_biases = np.random.rand(num_features) * importance_bias # True bias\n","\n","def f(x):\n","  # Create a mere linear equation\n","  f = true_weights * x + true_biases # y = w_1 * x_1 + b_1 + ... + w_n * x_n + b_n\n","  f = np.sum(f, -1)\n","  # Add noise to the data\n","  f = f + np.random.uniform(low=-1.0, high=1.0, size=(num_samples)) * importance_noise\n","  # Create outlier with a chance of 5%\n","  f = f + np.random.uniform(low=-1.0, high=1.0, size=(num_samples)) * np.random.choice([True, False], size = num_samples, p=[0.05, 0.95]) * outlier_value\n","  return f\n","\n","\n","data_output = f(data_input)"],"metadata":{"id":"ttbjzrGIGw6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the model\n","network = Sequential()\n","# Model will only have\n","network.add(Dense(1, input_shape=(num_features,)))\n","# Compile the model with mean squared error loss and SGD optimizer\n","network.compile(loss=\"mean_squared_error\", optimizer=SGD(learning_rate=0.01))\n","\n","# Train the model\n","network.fit(data_input, data_output, epochs=150, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JG9I75gTHjW1","executionInfo":{"status":"ok","timestamp":1722332747588,"user_tz":-420,"elapsed":12388,"user":{"displayName":"Minh Phạm Tuấn","userId":"10498019973223653458"}},"outputId":"27268064-2034-433a-9eea-75f603d7b36d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","32/32 [==============================] - 1s 2ms/step - loss: 1730540.7500\n","Epoch 2/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1721693.7500\n","Epoch 3/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720596.6250\n","Epoch 4/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1721965.6250\n","Epoch 5/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1721153.2500\n","Epoch 6/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720106.3750\n","Epoch 7/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720328.7500\n","Epoch 8/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720711.1250\n","Epoch 9/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720043.1250\n","Epoch 10/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719771.5000\n","Epoch 11/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719816.5000\n","Epoch 12/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720119.6250\n","Epoch 13/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720996.5000\n","Epoch 14/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1721329.6250\n","Epoch 15/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720090.7500\n","Epoch 16/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720123.1250\n","Epoch 17/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720814.6250\n","Epoch 18/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719891.2500\n","Epoch 19/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718714.5000\n","Epoch 20/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719512.6250\n","Epoch 21/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1721793.0000\n","Epoch 22/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1721031.5000\n","Epoch 23/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1721067.2500\n","Epoch 24/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718838.6250\n","Epoch 25/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719996.2500\n","Epoch 26/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718612.1250\n","Epoch 27/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718551.7500\n","Epoch 28/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719644.7500\n","Epoch 29/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719460.1250\n","Epoch 30/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718904.8750\n","Epoch 31/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719161.0000\n","Epoch 32/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719521.5000\n","Epoch 33/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1717836.5000\n","Epoch 34/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1721835.6250\n","Epoch 35/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719058.5000\n","Epoch 36/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718018.3750\n","Epoch 37/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1717909.2500\n","Epoch 38/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719797.2500\n","Epoch 39/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718402.7500\n","Epoch 40/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720722.7500\n","Epoch 41/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718647.1250\n","Epoch 42/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718945.1250\n","Epoch 43/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719373.7500\n","Epoch 44/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719154.7500\n","Epoch 45/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719623.8750\n","Epoch 46/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719137.1250\n","Epoch 47/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720941.6250\n","Epoch 48/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718986.3750\n","Epoch 49/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719550.8750\n","Epoch 50/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719133.5000\n","Epoch 51/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719771.1250\n","Epoch 52/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718481.7500\n","Epoch 53/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719354.1250\n","Epoch 54/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718533.7500\n","Epoch 55/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718983.3750\n","Epoch 56/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718136.2500\n","Epoch 57/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719023.0000\n","Epoch 58/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718700.0000\n","Epoch 59/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719033.0000\n","Epoch 60/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718717.6250\n","Epoch 61/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720301.5000\n","Epoch 62/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718205.0000\n","Epoch 63/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718656.1250\n","Epoch 64/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719458.3750\n","Epoch 65/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719763.3750\n","Epoch 66/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718571.6250\n","Epoch 67/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720541.5000\n","Epoch 68/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719347.5000\n","Epoch 69/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718817.3750\n","Epoch 70/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1717877.2500\n","Epoch 71/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720069.5000\n","Epoch 72/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719432.3750\n","Epoch 73/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718509.5000\n","Epoch 74/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719280.3750\n","Epoch 75/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719849.7500\n","Epoch 76/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718597.3750\n","Epoch 77/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718681.7500\n","Epoch 78/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719255.2500\n","Epoch 79/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719999.6250\n","Epoch 80/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718240.3750\n","Epoch 81/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719536.0000\n","Epoch 82/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719112.3750\n","Epoch 83/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718524.7500\n","Epoch 84/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720718.3750\n","Epoch 85/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718484.2500\n","Epoch 86/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720195.6250\n","Epoch 87/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719798.1250\n","Epoch 88/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719940.3750\n","Epoch 89/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718573.0000\n","Epoch 90/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719044.1250\n","Epoch 91/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718194.2500\n","Epoch 92/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720313.6250\n","Epoch 93/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719232.1250\n","Epoch 94/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718542.2500\n","Epoch 95/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719115.5000\n","Epoch 96/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719617.1250\n","Epoch 97/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719280.3750\n","Epoch 98/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719929.7500\n","Epoch 99/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718840.5000\n","Epoch 100/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719197.6250\n","Epoch 101/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719536.5000\n","Epoch 102/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719965.6250\n","Epoch 103/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719652.8750\n","Epoch 104/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718318.0000\n","Epoch 105/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718761.6250\n","Epoch 106/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718533.0000\n","Epoch 107/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718652.3750\n","Epoch 108/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719553.1250\n","Epoch 109/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718459.7500\n","Epoch 110/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1717881.2500\n","Epoch 111/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720165.7500\n","Epoch 112/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718566.3750\n","Epoch 113/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719104.0000\n","Epoch 114/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719029.0000\n","Epoch 115/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719248.2500\n","Epoch 116/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719065.6250\n","Epoch 117/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720183.7500\n","Epoch 118/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719046.5000\n","Epoch 119/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719410.1250\n","Epoch 120/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719535.6250\n","Epoch 121/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718900.1250\n","Epoch 122/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719824.3750\n","Epoch 123/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718822.8750\n","Epoch 124/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719176.2500\n","Epoch 125/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718842.3750\n","Epoch 126/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719145.8750\n","Epoch 127/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718747.1250\n","Epoch 128/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719483.5000\n","Epoch 129/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718772.2500\n","Epoch 130/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720122.5000\n","Epoch 131/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718334.6250\n","Epoch 132/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720154.2500\n","Epoch 133/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718735.0000\n","Epoch 134/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719323.5000\n","Epoch 135/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718811.8750\n","Epoch 136/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718102.1250\n","Epoch 137/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719907.0000\n","Epoch 138/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718112.3750\n","Epoch 139/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718804.3750\n","Epoch 140/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718846.0000\n","Epoch 141/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718954.7500\n","Epoch 142/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718876.7500\n","Epoch 143/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719545.6250\n","Epoch 144/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720061.0000\n","Epoch 145/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718132.6250\n","Epoch 146/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719180.1250\n","Epoch 147/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718941.0000\n","Epoch 148/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1718752.1250\n","Epoch 149/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1719237.0000\n","Epoch 150/150\n","32/32 [==============================] - 0s 2ms/step - loss: 1720152.5000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ffa56b8e2f0>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Retrieve the feature weights and total biases\n","weights, biases = network.layers[-1].get_weights()\n","print(f\"Weights: {weights.flatten()}\")\n","print(f\"Biases: {biases}\")\n","\n","# The initalize weights and biases\n","print(true_weights)\n","print(true_biases)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gtYCSbRHKYkA","executionInfo":{"status":"ok","timestamp":1722332747589,"user_tz":-420,"elapsed":32,"user":{"displayName":"Minh Phạm Tuấn","userId":"10498019973223653458"}},"outputId":"54472fc7-ef05-447f-effc-bb3ad4834a8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Weights: [ 57.69515   45.928505 -56.552544  13.436747 186.17789 ]\n","Biases: [42.657295]\n","[39.36355203 47.34356594 85.45473932 34.00043861 86.96496848]\n","[0.88134431 7.76798437 8.47547633 1.81817653 4.30346532]\n"]}]},{"cell_type":"code","source":["# Generate test data\n","test_input = np.random.rand(20, num_features)  # 20 samples\n","test_input = np.sort(test_input)\n","\n","def f(x):\n","  f = true_weights * x + true_biases\n","  f = np.sum(f, -1)\n","  return f\n","\n","test_output = f(test_input) # Create linear data without noise or outlier\n","predictions = network.predict(test_input)\n","percentage_errors = [abs(predictions[i][-1] - test_output[i]) / abs(test_output[i]) * 100\n","                     for i in range(len(test_output))] # Calculate the percentage of difference\n","for i in range(len(test_input)):\n","    print(f\"Input: {test_input[i]}, True Output: {test_output[i]}, Predicted Output: {predictions[i][-1]},\n","    Loss: {percentage_errors[i]:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPT07FymLvaR","executionInfo":{"status":"ok","timestamp":1722332952719,"user_tz":-420,"elapsed":550,"user":{"displayName":"Minh Phạm Tuấn","userId":"10498019973223653458"}},"outputId":"4b1bd70c-1bff-4fd5-ada3-659571a76646","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n","Input: [0.30521453 0.40823752 0.49961841 0.66336261 0.97374258], True Output: 204.51906865624767, Predicted Output: 240.96450805664062, Loss: 17.82%\n","Input: [0.17170999 0.24218345 0.28046322 0.52983389 0.73110298], True Output: 147.03323407435755, Predicted Output: 191.060791015625, Loss: 29.94%\n","Input: [0.11793867 0.28329653 0.28998739 0.62890514 0.6549411 ], True Output: 144.42198021138734, Predicted Output: 176.45962524414062, Loss: 22.18%\n","Input: [2.42934435e-04 1.26936058e-01 2.33609032e-01 8.67354639e-01\n"," 9.33615378e-01], True Output: 159.91088424246752, Predicted Output: 220.7630615234375, Loss: 38.05%\n","Input: [0.37360566 0.60857159 0.68146061 0.7783719  0.97090471], True Output: 235.89856481282737, Predicted Output: 244.84475708007812, Loss: 3.79%\n","Input: [0.06353572 0.2878795  0.39624735 0.53898087 0.96381766], True Output: 175.38185321487703, Predicted Output: 223.81976318359375, Loss: 27.62%\n","Input: [0.12027096 0.37393871 0.64485604 0.70352834 0.95094135], True Output: 207.40919324388926, Predicted Output: 216.7999267578125, Loss: 4.53%\n","Input: [0.02220281 0.25225283 0.30372385 0.32093544 0.92106949], True Output: 153.03034419990013, Predicted Output: 214.14263916015625, Loss: 39.93%\n","Input: [0.10314676 0.53422041 0.79507288 0.82380175 0.94302071], True Output: 230.5607018706313, Predicted Output: 214.81973266601562, Loss: 6.83%\n","Input: [0.18125026 0.38495872 0.40229468 0.71200796 0.78329009], True Output: 175.31178741456142, Predicted Output: 203.44271850585938, Loss: 16.05%\n","Input: [0.12665587 0.37631182 0.42063024 0.48094161 0.96278481], True Output: 182.07363856566224, Predicted Output: 229.1719970703125, Loss: 25.87%\n","Input: [0.05226867 0.1947938  0.36318912 0.43621442 0.68553862], True Output: 140.01171844849878, Predicted Output: 167.57369995117188, Loss: 19.69%\n","Input: [0.29845066 0.48639163 0.63809273 0.80256075 0.8160335 ], True Output: 210.8038319056621, Predicted Output: 208.84112548828125, Loss: 0.93%\n","Input: [0.04032524 0.09476847 0.23600793 0.28815214 0.73051465], True Output: 122.81494792097342, Predicted Output: 175.86709594726562, Loss: 43.20%\n","Input: [0.00678817 0.06899001 0.15294319 0.28880997 0.99580237], True Output: 136.2691938430441, Predicted Output: 226.84524536132812, Loss: 66.47%\n","Input: [0.14926801 0.24099626 0.3648181  0.52016022 0.93612557], True Output: 170.8030301493548, Predicted Output: 222.981689453125, Loss: 30.55%\n","Input: [0.20728252 0.33500857 0.37779682 0.39499027 0.87339146], True Output: 168.9351557025351, Predicted Output: 216.55111694335938, Loss: 28.19%\n","Input: [0.06589217 0.2895827  0.31668436 0.57719975 0.67730396], True Output: 145.13901550830832, Predicted Output: 175.7044677734375, Loss: 21.06%\n","Input: [0.19128916 0.37725199 0.40740527 0.66407412 0.93694925], True Output: 187.5120068028284, Predicted Output: 231.34280395507812, Loss: 23.37%\n","Input: [0.0585366  0.12703358 0.15766103 0.25508722 0.3054135 ], True Output: 80.27111251314705, Predicted Output: 103.24168395996094, Loss: 28.62%\n"]}]},{"cell_type":"code","source":["## Only use for one feature\n","## Plot the test data and the linear equation that model predicts\n","# sorted_indices = np.argsort(test_input.flatten())\n","# sorted_test_input = test_input[sorted_indices]\n","# sorted_test_output = test_output[sorted_indices]\n","# plt.scatter(sorted_test_input, sorted_test_output)\n","# w = weights.flatten()\n","# b = biases\n","# plt.plot(sorted_test_input, w * sorted_test_input + b, color='red')\n","# plt.plot()\n","# plt.show()"],"metadata":{"id":"33zYgXTzoF0c"},"execution_count":null,"outputs":[]}]}